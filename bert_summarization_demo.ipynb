{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pytorch入门实战（7）：基于BERT实现简单的中文文本摘要任务（Summarization task）"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Globe Config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "text_max_length = 512\n",
    "summary_max_length = 48\n",
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\iiosn\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\amazon_reviews_multi\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609 (last modified on Wed Aug 10 20:35:47 2022) since it couldn't be found locally at amazon_reviews_multi., or remotely on the Hugging Face Hub.\n",
      "Reusing dataset amazon_reviews_multi (C:\\Users\\iiosn\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\zh\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90ad62996a5c43058d5661932c551edc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"amazon_reviews_multi\", \"zh\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'review_id': 'zh_0626061',\n 'product_id': 'product_zh_0691762',\n 'reviewer_id': 'reviewer_zh_0824776',\n 'stars': 1,\n 'review_body': '本人账号被盗，资金被江西（杨建）挪用，请亚马逊尽快查实，将本人的200元资金退回。本人已于2017年11月30日提交退货申请，为何到2018年了还是没解决？亚马逊是什么情况？请给本人一个合理解释。',\n 'review_title': '此书不是本人购买',\n 'language': 'zh',\n 'product_category': 'book'}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset And Dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mode='train'):\n",
    "        super(SummarizationDataset, self).__init__()\n",
    "        self.dataset = dataset[mode]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        text = data['review_body']\n",
    "        summary = data['review_title']\n",
    "        return text, summary\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.dataset)\n",
    "        return 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "train_dataset = SummarizationDataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # print(batch)\n",
    "    text, summary = zip(*batch)\n",
    "    text, summary = list(text), list(summary)\n",
    "\n",
    "    # src是要送给bert的，所以不需要特殊处理，直接用tokenizer的结果即可\n",
    "    src = tokenizer(text, padding='max_length', max_length=text_max_length, return_tensors='pt', truncation=True)\n",
    "    tgt = tokenizer(summary, padding='max_length', max_length=summary_max_length, return_tensors='pt', truncation=True)\n",
    "\n",
    "    tgt_y = {}\n",
    "    for key, value in tgt.items():\n",
    "        tgt_y[key] = value[:, 1:]\n",
    "\n",
    "    for key, value in tgt.items():\n",
    "        tgt[key] = value[:, :-1]\n",
    "\n",
    "    n_tokens = tgt_y['attention_mask'].sum().item()\n",
    "\n",
    "    return src, tgt, tgt_y, n_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class SummarizationModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SummarizationModel, self).__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=768, nhead=8, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "        self.embeddings = self.bert.embeddings\n",
    "        self.predictor = nn.Linear(768, tokenizer.vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        last_hidden_state = self.bert(**src).last_hidden_state\n",
    "        decoder_inputs = self.embeddings(tgt['input_ids'])\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt['input_ids'].size(-1)).to(device)\n",
    "        tgt_key_padding_mask = tgt['attention_mask'] == 0\n",
    "        decoder_outputs = self.decoder(tgt=decoder_inputs, memory=last_hidden_state, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        return decoder_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model = SummarizationModel()\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class SummarizationLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SummarizationLoss, self).__init__()\n",
    "        self.criteria = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    def forward(self, outputs, tgt_y, n_tokens):\n",
    "        targets = tgt_y['input_ids'].flatten()\n",
    "        outputs = outputs.view(-1, tokenizer.vocab_size)\n",
    "\n",
    "        return self.criteria(outputs, targets) / n_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "criteria = SummarizationLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss:{} tensor(1.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.9838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.8144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.7552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.6837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.6363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.6121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.5796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.5673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.5434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.5082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.4862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.4640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.3891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.2914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.1651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.1186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "total loss:{} tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-410d3c6ced6d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriteria\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtgt_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_tokens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\optim\\optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m                 \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 88\u001B[1;33m                     \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     89\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\optim\\adam.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    139\u001B[0m                     \u001B[0mstate_steps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'step'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m             F.adam(params_with_grad,\n\u001B[0m\u001B[0;32m    142\u001B[0m                    \u001B[0mgrads\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m                    \u001B[0mexp_avgs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\optim\\_functional.py\u001B[0m in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m         \u001B[1;31m# Decay the first and second moment running average coefficient\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 97\u001B[1;33m         \u001B[0mexp_avg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbeta1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mbeta1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     98\u001B[0m         \u001B[0mexp_avg_sq\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbeta2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maddcmul_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconj\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mbeta2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     99\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mamsgrad\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "total_loss = 0.\n",
    "step = 0\n",
    "\n",
    "def to_device(dict_tensors):\n",
    "    result_tensors = {}\n",
    "    for key, value in dict_tensors.items():\n",
    "        result_tensors[key] = value.to(device)\n",
    "    return result_tensors\n",
    "\n",
    "for epoch in range(10000):\n",
    "    for batch in train_loader:\n",
    "        src, tgt, tgt_y, n_tokens = batch\n",
    "        src, tgt, tgt_y = to_device(src), to_device(tgt), to_device(tgt_y)\n",
    "        outputs = model(src, tgt)\n",
    "        outputs = model.predictor(outputs)\n",
    "        loss = criteria(outputs, tgt_y, n_tokens)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss\n",
    "        step += 1\n",
    "\n",
    "        if step % 1 == 0:\n",
    "            print(\"total loss:{}\", total_loss)\n",
    "            total_loss = 0\n",
    "\n",
    "\n",
    "        # del batch, src, tgt, tgt_y, outputs\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.1375,  0.0668, -0.2818,  ..., -1.1806,  0.0993, -0.1572],\n         [-0.8236,  0.5126,  0.0020,  ..., -0.1308, -0.0932,  0.4920],\n         [-0.5635, -0.8716,  0.3278,  ...,  0.2668, -0.8484,  0.1565],\n         ...,\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n       device='cuda:0', grad_fn=<CopySlices>)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([9.8903e-01, 9.8789e-01, 9.8701e-01, 9.8842e-01, 9.8890e-01, 9.9022e-01,\n        9.8810e-01, 9.8694e-01, 9.8804e-01, 4.7331e-05, 4.7331e-05, 4.7331e-05,\n        4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05,\n        4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05,\n        4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05,\n        4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05,\n        4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05,\n        4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05, 4.7331e-05],\n       device='cuda:0', grad_fn=<MaxBackward0>),\nindices=tensor([3634,  741,  679, 3221, 3315,  782, 6579,  743,  102,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n       device='cuda:0'))"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(dim=-1)(outputs.view(-1, tokenizer.vocab_size)).max(dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8949, device='cuda:0', grad_fn=<DivBackward0>)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria(outputs, tgt_y, n_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "outputs[:, 9:, 0] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.1375,  0.0668, -0.2818,  ..., -1.1806,  0.0993, -0.1572],\n         [-0.8236,  0.5126,  0.0020,  ..., -0.1308, -0.0932,  0.4920],\n         [-0.5635, -0.8716,  0.3278,  ...,  0.2668, -0.8484,  0.1565],\n         ...,\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n       device='cuda:0', grad_fn=<CopySlices>)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AsStridedBackward0>) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria(outputs, tgt_y, n_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n       device='cuda:0')"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_y['input_ids']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n        device='cuda:0'),\n 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n        device='cuda:0'),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n        device='cuda:0')}"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}